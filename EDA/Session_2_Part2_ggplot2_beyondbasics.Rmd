---
title: "Intro to R and Data Visualization with ggplot2: Session 2 part 2"
subtitle: UCI Data Science Initiative
params: 
  reportdate: "`r format(Sys.time(), '%d %B %Y')`"  # to be replaced
date: "`r format(Sys.time(), '%d %B %Y')`"
author: "Arnold Seong"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css:
      - default
      - default-fonts
      - "https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.0/animate.min.css"
      - xaringan-themer.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false

  
# output:
#   html_document:
#     highlight: tango

---



```{r setup, include=FALSE, message=F, echo=F, warning=F}
library(xaringanthemer)
# style_xaringan(
  # code_inline_background_color = "#C0C0C0"
#   text_font_family = "Droid Serif",
#   text_font_url = "https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic",
#   header_font_google = google_font("Yanone Kaffeesatz")
# )
style_mono_accent(base_color = "#3C989E")

# knitr::opts_chunk$set(cache=FALSE, warning=FALSE, message=FALSE, echo=TRUE, warning=FALSE, error=FALSE)
knitr::opts_chunk$set(cache=TRUE, warning=TRUE, message=TRUE, echo=TRUE, warning=TRUE, error=TRUE
                      , figure.width=7, figure.width=5
                      )

#set scientific notation digit threshold
options(scipen=10)

#load libraries
library(knitr)
library(RColorBrewer)
```

layout: true

<style>
pre {
    display: block;
    font-family: monospace;
    white-space: pre;
    margin: 1em 0px;
    margin-top: 0.5em;
    margin-right: 0px;
    margin-bottom: 0em;
    margin-left: 0px;
}
.remark-inline-code {
  background: #F5F5F5; 
}
</style>


<!-- xaringan::inf_mr() -->

---
class: animated, fadeIn

## Workshop info
+ We will be recording today's sessions for potential future use
    + You may not want to activate video
    + Please set your zoom to mute your audio until you would like to speak
    + You can change your icon name by mousing over, clicking on the 3 dots
    
+ Please ask questions during lectures & throughout the day!
    + Use chat
    + Raise hand (`Alt+Y`)
    + Unmute yourself temporarily (hold `Spacebar`).


<!-- + To access course materials please visit the [IDA-with-R website](https://ucidatascienceinitiative.github.io/IDA-with-R/). -->
<!-- + **Please [download](https://github.com/UCIDataScienceInitiative/IDA-with-R/archive/master.zip) & unzip the Github repository!** -->


---
class: inverse
## Session 2 Topics

1.  Introduction to ggplot2 and the "grammar of graphics"
  - understanding the logic of ggplot2
  - overlaying geoms
  - visualizing strata for comparison
1. Beyond ggplot2 basics
  - preparing and plotting data
  - changing default plot options



---
class: inverse, animated, fadeIn
## Session 2 Topics

1. **Introduction to ggplot2 and the "grammar of graphics"**
  - **understanding the logic of ggplot2**
  - **overlaying geoms**
  - **visualizing strata for comparison**
1. Beyond ggplot2 basics
  - preparing and plotting data
  - changing default plot options





---
## Intro to session 2 part 2
- more specific EDA as illustration

- goal is not to cover every command comprehensively

- discuss merging new data, but not how to get the data








---
## Longitudinal EDA: observation table
For longitudinal data, one important indication of data quality is the number of times you observe your subjects.

You can use the `table()` function for this, which counts how many times a particular value appears in the data.  

--

#### &nbsp;

`table()` is typically used for factor levels

```{r}
library(ggplot2)
table(diamonds$cut)
```






---
## Longitudinal EDA: observation table
For longitudinal data, one important indication of data quality is the number of times you observe your subjects.

You can use the `table()` function for this, which counts how many times a particular value appears in the data.  


#### &nbsp;

`table()` is typically used for factor levels ... and to make contingency tables:

```{r}
table(diamonds$cut, diamonds$color)
```






---
## Observation table (2)
Here we'll use the NYTimes dataset from before, `ct`

```{r, eval=F}
table(ct$fips)[1:60] # just the first 60
```

--

```{r, echo=F}
load("data/ct.Rdata")
table(ct$fips)[1:60]
```


Each entry is named with the value in `fips`, and tells us how many times it appears in our data.
--

```{r}
length(table(ct$fips))
```

--

Now it's much easier to sift through these by hand and look for patterns!





---
## Observation table (3)

Not really.  Instead, we run table on it again.

```{r, eval=F}
table(table(ct$fips))
```

--

```{r, echo=F}
table(table(ct$fips))
```

--

Now the patterns are much clearer!





---
## Observation table (4)
Ok, sorry.  That's not very helpful at all.

Actually, `table(table( <unique_subj_ID> ))` *is* usually helpful to see, for example, 

--

- how many of the 15 planned followups that patients in your study attended 

--

- if you subset the data to the first, middle, and last 5, the areas where you have the most observations

--

i.e. to start identifying where the data may be **sparse** or **rich**.


???

PRESENTER NOTES:

i.e. studies with relatively limited numbers of planned followups

**For the NYTimes COVID-19 data, our situation is a little different**
What information would we get from knowing the number of observations we have of each county?

Yes, we get a sense of data quality 

But the **most direct implication** of # of obs is
- earlier / later detection in the county
- likely correlated with present number of cases
  - discrepancies could be interesting, especially if descrepancies were mapped

**There are better plots for these.  This is just a starting point.**






---
## Observation table (5)
That's not true here.  There's just too much.  So, instead, we'll plot it.

```{r, fig.height=5}
plot(table(table(ct$fips)))
```

???
PRESENTER NOTES:

- data quality - lots of high counts (we knew that), should be able to get a good sense of the time course and trajectory over time
  - might be interesting to subset to urban / rural areas

Once we have better understanding of when the virus entered communities (i.e. via genomic analysis).  
- Count the days since entrance
- table that by county and plot it
- comparison of these:  
    - if the plot is the ssame, just shifted, we get a sense of the lag between virus entrance and detection
    - if the plot is significantly different, that tells us certain counties were quicker/slower to respond

**There are better plots for these.  This is just a starting point.**






---
## Observation plot in ggplot2

Remember that we wanted to see if, after a county enters the dataset, it stays in the dataset?  

One nice thing about having dates of observations is that we can plot each county by date.  Let's take a first shot.

- going to use `geom_raster()` here: draws tiles of same size centered at (x,y) coords




---
## Observation plot in ggplot2
```{r}
ggplot(data=ct, aes(x=date, y=factor(fips))) +
  geom_raster(aes(fill=cases))
```

???
Not a great plot.  But it would have been SOOOOOOO much harder in base R.

Pose Question:  plotting-related problems?

- way too many factor levels to show at once
    - even if could see, rownames not informative
- scale of cases - hides everything (zooming in shows some very, very small blue lines)

larger version: https://github.com/akseong/IntroEDA_Rggplot2/blob/master/images/num_obs_by_date_bad.png






---
## Observation plot in ggplot2
Problems:

- too many rows to see anything.
--
  **So subset!**

--


- even if we could see them, the `fips` codes would not be informative.
--
  **so choose different identifier**

--

- color scheme is bad for this data (mostly very low numbers, a handful of extremely high numbers)
--
  **re-scale the numbers, or discretize**





---
## Observation plot in ggplot2: attempt 2
```{r, eval=F}
ggplot(data=subset(ct, state=="California"), aes(x=date, y=county)) +
  geom_raster(aes(fill=cut(cases, quantile(cases, probs=seq(0, 1, .1), na.rm=T))))

```

--
```{r, echo=F, fig.width=10, fig.height=6}
ggplot(data=subset(ct, state=="California"), aes(x=date, y=county)) +
  geom_raster(aes(fill=cut(cases, quantile(cases, probs=seq(0, 1, .1), na.rm=T))))

```

???
(changed slide plot window size manually to be super wide)

Problems?  
- stupid legend name takes up the whole plot window!
- color scale is nausea-inducing.
- factor (row) order is just alphabetical





---
## Attempt 2 post-mortem
Problems:

- stupid legend name!  
--
**We already did this with `labs()`**

  - Probably don't need the "county" label either.

--

- color scheme = unicorn vomit.  
--
**Need to learn about color scaling**

--

- y-axis text a little too large.  
--
**Getting more complicated**


--
but the overall skeleton of the plot seems like what we want, so let's save it for now.

```{r}
CAdate_plt <- ggplot(data=subset(ct, state=="California"), aes(x=date, y=county)) +
  geom_raster(aes(fill=cut(cases, quantile(cases, probs=seq(0, 1, .1), na.rm=T))))
```







---
## ggplot2: beyond defaults

In addition to the 3 key elements (**data, aesthetic mapping, geom/stat layers**), there are many other components in a plot.

Any of you who have had to prepare publication-quality plots for a journal is aware of this.

--

We'll mention how to manipulate some of those plotting parameters (e.g. text size, tick marks, etc.) in a moment.

--

But for now let's get rid of the unicorn vomit.






---
## Scales
`ggplot2` calls the *particular* values that a mapping takes a **scale**.

In other words, a scale determines the correspondence between values in your data and the visual values in the plot.

--

For example:

  - axis transformations, e.g. `scale_x_log10()`, `scale_y_reverse()`
  - a size mapping, e.g. `scale_size_discrete()`
  - color mapping, e.g. `scale_fill_continuous()`


(More info on scales in the [ggplot2 book](https://ggplot2-book.org/scales.html))

--

For example, instead of cutting by quantiles, we could have scaled the data values to the gradient values using log base 10.




---
## Better than unicorn vomit

```{r, fig.width=6, fig.height=4.5}
ggplot(data=subset(ct, state=="California"), aes(x=date, y=county)) +
  geom_raster(aes(fill=cases)) +
  scale_fill_continuous(trans="log10",    # transformation
                        breaks=10^(1:6),  # define legend breaks 
                        labels=10^(1:6))  # define legend labels
```

???
prefer discrete scale to gradient






---
## ggplot2: discrete variable color scaling
- by default, for unordered factors, `ggplot2` picks colors as far apart on the color wheel as possible. 

  - this is why we obtained unicorn vomit

--

- for ordered factors, the default is the `viridis` palette. 

  - [viridis vignette here](https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html)

--

You can define your own colors if you want.  
--
But you're not a graphic designer.

--

The built-in palettes (`RColorBrewer` and `viridis` palettes) usually do the job well.  

???
In general, sticking to 1 or 2 color palettes is desirable, and the `viridis` palettes are pleasing and have desirable properties.
viridis - gradient palettes optimized for contrast (same contrasts in black-and-white as in color) and color-blindness
- viridis is a little angsty
- RColorBrewer is a bit more cheerful




---
## Built-in palettes
Since we saved our plot, we can test out some color schemes relatively easily.


We'll try a few in the next slides.

--

- to use the `viridis` palettes, we add a discrete fill-color scale using `scale_fill_viridis_d()`

  - can specify `option = magma`, or `inferno`, `plasma`, `viridis` (default), `cividis`
  - for continuous variables, use `scale_fill_viridis_c()`

--

- to use the ColorBrewer palettes, use `scale_fill_brewer()` and specify a palette (`RColorBrewer::display.brewer.all()` to see them)

???
mention the ::



---
## viridis default

```{r, message=F}
CAdate_plt +
  scale_fill_viridis_d() +
  theme(legend.position = "none")
```

???
Mention `theme(legend.position = "none")` 
Will talk about in next chunk


---
## viridis "plasma"

```{r, message=F}
CAdate_plt +
  scale_fill_viridis_d(option="plasma") +
  theme(legend.position = "none")
```

---
## viridis "magma"

```{r, message=F}
CAdate_plt +
  scale_fill_viridis_d(option="magma") +
  theme(legend.position = "none")
```

---
## ColorBrewer "Spectral"

```{r, message=F}
CAdate_plt +
  scale_fill_brewer(palette="Spectral") +
  theme(legend.position = "none")

```

---
## ColorBrewer "Spectral", reverse direction

```{r, message=F}
CAdate_plt +
  scale_fill_brewer(palette="Spectral", direction=-1) +
  theme(legend.position = "none")

```






---
## ggplot2: themes

ggplot2 has a `theme()` argument you can use to change many other things about the appearance of the plot.

- you can see the options here: [ggplot2 `theme()` reference page](https://ggplot2.tidyverse.org/reference/theme.html)

--

There are default themes (e.g. `theme_bw()`, `theme_classic()`, `theme_dark()` etc.) 

- you can use these as a base theme, then change individual theme elements using `theme()`




---
## Final plot
You might remember we wanted to do a few things:
1. choose a better color palette
1. shorten legend title, remove axis labels
1. make y-axis text smaller


```{r, eval=F, fig.width=10, fig.height=6, message=F}
CAdate_plt +
  scale_fill_viridis_d(option="plasma", direction=-1) +
  labs(title="COVID-19 cumulative cases (deciles) by date",
       subtitle="counties in California",
       x="",
       y="",
       fill="case counts \n (by decile)") +
  theme_classic()+
  theme(axis.text.y=element_text(size=7))
```

???
Note on last line - fixes the size.  
Usually if you resize, ggplot2 will resize these as well.
Now it won't.


---

```{r, echo=F, fig.width=10, fig.height=8}
CAdate_plt +
  scale_fill_viridis_d(option="plasma", direction=-1) +
  labs(title="COVID-19 cumulative cases (deciles) by date",
       subtitle="counties in California",
       x="",
       y="",
       fill="case counts \n (by decile)") +
  theme_classic()+
  theme(axis.text.y=element_text(size=7))
```

???
legend labels are not great.  Could fix those manually.

Why might this be better than a line plot for our dataset?
- y-scale - discretizing a line plot doesn't make much sense
- emphasizes benchmark dates
  - date of entry
  - date of "progression" into next decile






---

## longitudinal EDA: spaghetti plot
In a longitudinal analysis, a line plot of individual subject trajectories (a 'spaghetti plot') can provide a lot of useful information, e.g. intra- versus inter-subject/group variation.

Quick illustration using the `Indometh` dataset (in base R):
```{r, echo=F}
Indometh$Subject <- factor(Indometh$Subject, levels=1:6, ordered=FALSE)
```

--

.pull-left[
```{r, fig.width=5, fig.height=3}
ggplot(Indometh, aes(x=time, y=conc)) + 
  geom_line(aes(color=Subject)) 
```
]

--

.pull-right[
```{r, fig.width=5, fig.height=3}
ggplot(Indometh, aes(x=time, y=log(conc))) + 
  geom_line(aes(color=Subject)) 
```
]


???
2 lines!  base R would require at least a loop.

If we had different groups, could specify group=Subject and color=group.
Could also facet-wrap.
Ways of plotting all lines (faded) with group darkened in facet-wrap




---
## line plot for nytimes data

```{r, figure.width=10, figure.height=5}
ggplot(ct, aes(x=date, y=cases, color=county)) +
  geom_line() +
  theme(legend.position="none")
```



---
## line plot post-mortem
Problems:

- what's with the vertical lines?  
--
**remember the end of Exercise 1?  Need to fix.**

--

- scale of y-axis - a few observations dominates everything  
--
**rescale, or subset**

--

- so many different factor levels a legend is impossible
  - so... group and... average? sum? group by state? by region?  politics?
  - choropleth map will be nice, but mostly for showing one date only



???
coloring by county is problematic - remember from the end of exercise 1?.
- 4 states have an Adair county
```{r}
unique(subset(ct, county=="Adair")$state)
```
- could color by `fips`, but uninterpretable.




---
## Data manipulation: fix county factor

Different states may share a county with the same name, but a county-state pair should be unique.

- alternative: when showing a legend, could color by `fips` but coerce the legend to display the county names.  

  - not a great solution: requires repeated coding by hand.
  
--

#### &nbsp;

- using full state names will also make the legends really wide (when we can show them).  Let's use abbreviations.  

  - luckily R has built-in state name and abbreviation vectors, and a `match()` function
  
  





---
## test our matching code

```{r}
# make a test vector of state names  
st_test <- sample(c(state.name), 10, replace=T)
```
--
```{r}
# match them to the abbreviations 
abbs_test <- state.abb[match(st_test, state.name)]
```
--
```{r}
# check  
cbind(st_test, abbs_test)
```

--

Cool!  Let's do it!





---
## one more function we need: `paste0()`

- `paste0()` concatenates any number of (vectors of) strings, preserving spaces/punctuation.

- We saw it in Session 1, but here it is again:

```{r, eval=F}
paste0(1:5, "+", 1:5, "=", 2*1:5)
```
--
```{r, echo=F}
paste0(1:5, "+", 1:5, "=", 2*1:5)
```

???
Useful for debugging functions or loops
- use it in a print command with the iteration number and output you want to check




---
## fixing the county factor

```{r}
ct$countyst <- paste0(ct$county, 
                      " ",         # add a space
                      state.abb[match(ct$state, state.name)])
```

--

```{r}
# check
ct[sample(1:nrow(ct), 5), c("county", "state", "countyst")]
```




---
## line plot one more time

```{r, fig.width=10, fig.height=5.5}
ggplot(ct, aes(x=date, y=cases, color=countyst)) +
  geom_line() +
  theme(legend.position="none")
```





---
## add some text

```{r, fig.width=10, fig.height=5}
ggplot(ct, aes(x=date, y=cases, color=countyst)) +
  geom_line() +
  geom_text(data=subset(ct, date==max(date) & cases>45000),
            aes(x=date-10, y=cases, label=countyst),
            color="grey30") +
  theme(legend.position="none")
```




---
## log-scaled

```{r, fig.width=10, fig.height=5.5}
ggplot(subset(ct, cases>0), aes(x=date, y=cases, color=countyst)) +
  geom_line() +
  theme(legend.position="none") + 
  scale_y_log10()
```

???
- subsetted to cases>0 (176 cases=0) because log(0)=-inf
- some odd vertical lines - believe these are the "unknown" counties


---
## log-scaled

```{r, fig.width=10, fig.height=5.5}
ggplot(subset(ct, cases>0 & county !="Unknown"), 
       aes(x=date, y=cases, color=countyst)) +
  geom_line() +
  theme(legend.position="none") + 
  scale_y_log10()
```

???
best we're going to get in terms of a wholistic picture of trajectories




---
## subset to CA
```{r, fig.width=10, fig.height=5.5}
ggplot(subset(ct, state=="California"), 
       aes(x=date, y=cases, color=countyst)) +
  geom_line() 
```


---
## subset to CA, log-scaled y-axis
```{r, fig.width=10, fig.height=5.5}
ggplot(subset(ct, state=="California" & cases>0), 
       aes(x=date, y=cases, color=countyst)) +
  geom_line() + 
  scale_y_log10(breaks=c(10, 50, 100, 500, 1000, 5000, 10000))
```



---
## re-order the factor levels

Legends for discrete variables are ordered by the factor level.  As an exercise, you'll re-order the factor levels and subset so that the previous plots for CA are actually readable.





---
## Data transformation with the `dplyr` package
`dplyr` is a fantastic package for manipulating data, especially complex data

*Advantages*

- much easier to work with data with grouped observations

- particularly, for large datasets when you may not want to continually duplicate your data, the code is much more readable.

--

*Disadvantages* 

--

- likely none if it's how you grew up


???
Grouped obs data - often need to use the "split-apply-combine" strategy.  Much easier and clearer in dplyr





---
## `dplyr` example for "split-apply-combine" strategy

For example, to get day-to-day differences in case counts:

Base R version:

```{r, eval=F}
ct$case_diffs <- unlist(lapply(split(ct, ct$countyst), function(x) c(NA, diff(x$cases)))))
```
--
The last operation comes first, and you kind of have to read from the middle out.

--

`dplyr` version:
```{r}
library(dplyr)
ct <- ct %>%
  group_by(countyst) %>%  # group your data by countyst
  arrange(date) %>%       # order (and implement the order) within the groups
  mutate(case_diffs = c(NA, diff(cases)))  # add a new variable
```


???

Syntactically it's a little like the difference between:
- "The cat scratched the dog.  The dog bit the man.  The man ran away."
- "The dog the cat scratched bit the man, who ran away" 
    - or perhaps "The man the dog the cat scratched bit ran away."




---
## `dplyr` on nytimes data
Let's use it!

```{r}
# max observed cases for county (used to subset)
ct <- ct %>%
  group_by(countyst) %>%
  mutate(maxcases = max(cases))

# add column of day-to-day differences
ct <- ct %>%
  group_by(countyst) %>%
  arrange(date) %>%
  mutate(diffs_cases = c(NA, diff(cases)))

# create a sliding window average
ct <- ct %>%
  group_by(countyst) %>%
  arrange(date) %>%
  mutate(diffs_roll = data.table::frollmean(diffs_cases, n=7, na.rm=T))
```




---
## some more `dplyr`
```{r}
# order factor levels by most recent # cases
# use ct_last to define order
ct_last <- ct %>%
  filter(date==max(date)) %>%
  arrange(cases, state, county) %>%
  select(county, state, countyst, cases)

#re-order the factor levels
ct$countyst <- factor(ct$countyst,
                      levels=rev(unique(ct_last$countyst)),
                      ordered=TRUE)
```

???
Explain why ordering the factor is helpful



---
## plot with ordered factors 
```{r, fig.width=10, fig.height=8}
ggplot(subset(ct, state=="California" & maxcases>500), 
       aes(x=date, y=cases, color=countyst)) +
  geom_line() + 
  scale_y_log10(breaks=c(10, 50, 100, 500, 1000, 5000, 10000)) +
  labs(title="cumulative case counts, log-scaled",
       subtitle="California counties with > 500 cases",
       color="county name \n (ordered by # cases)")

```



---
## Merging data

Finally, let's go over a bit of data augmentation before the break + exercise.

--

- One highly informative variable that we are missing is county population.

- Let's grab it from the Census Bureau

--

```{r}
cens <- read.csv("https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/co-est2019-alldata.csv")
dim(cens)
```

--
We don't need 164 variables... we just need 
1. county population and
1. a unique county identifier (that matches one in `ct`)






---
## Census data

If we look at the data (even a single row won't fit on a slide, so you'll have to do it yourself), we can identify some of the variables we need.

We'll take:
- `POPESTIMATE2019`: 2019 population estimate
- `CTYNAME`: county name
- `STNAME`: state name
- `STATE`: fips code for state
- `COUNTY`: fips code for county

```{r}
cens <- data.frame("pop2019" = cens$POPESTIMATE2019,
                   "county" = cens$CTYNAME,
                   "state" = cens$STNAME,
                   "fips_st" = cens$STATE,
                   "fips_ct" = cens$COUNTY)
```




---
## Census data, select variables

```{r, echo=F}
knitr::kable(head(cens), 'html')
```

--

What issues are we going to have joining this with the nytimes data?  

--

We need:
1. the population by county
1. a unique identifier for each county that is shared between the datasets




---
## Census data difficulties

- Complete state totals are in the data (i.e. first line)

--

- FIPS codes split up into state (first 2 digits) and county (last 3 digits)

--

- County names formatted differently - see name + "County" in the head, but there's more:

```{r}
library(stringr)
ct_words <- str_split(cens$county, pattern=" ")
last_words <- unlist(lapply(ct_words, function(x) x[ifelse(length(x)>1, length(x), 0)]))
table(last_words)
```








---
## function to combine FIPS

```{r}
#fips codes: 2-digit state + 3-digit county
combine_fips <- function(f_st, f_ct){
  # f_ct=0 indicates a state total
  f_ct <- ifelse(f_ct==0, NA, f_ct) 
  
  # count # digits in county FIPS code
  # & how many 0s needed between codes
  num_dig <- 1+floor(log(f_ct, 10)) 
  num_0s <- 3-num_dig 
  
  # stick num0s 0s between the state and county codes
  if(is.na(num_0s)){
    return(NA)
  } else if (num_0s==0){
    return(as.numeric(paste0(f_st,f_ct)))
  } else if (num_0s==1){
    return(as.numeric(paste0(f_st, "0", f_ct)))
  } else if (num_0s==2){
    return(as.numeric(paste0(f_st, "00", f_ct)))
  }
}
```





---
## apply function combine_fips()

```{r}
cens$fips <- apply(cens, 1, function(x) combine_fips(f_st=as.numeric(x["fips_st"]), 
                                                     f_ct=as.numeric(x["fips_ct"])))
```


Quick comment:
- this won't work without `as.numeric()`

--

- `apply()` treats the row as a vector

--

- b/c `cens` contains columns of strings, the row-vector is treated as a character vector

--

i.e., understanding how data typing works is actually helpful.



---
## merge datasets using left_join()

Use the `join()` functions from `dplyr` to merge tables easily.
- `left_join(x,y, by="var_name")` matches entries in var_name between x and y, and joins the row in y to the corresponding rows in x
- the other `join()` functions work similarly

--

So... let's do it!

--

I like to save it as something else, just in case.

```{r, warning=T, message=T, error=T}
ct_test <- left_join(ct, cens, by="fips")
```
--
...Dangit.  




---
## Ok, relatively easily.

```{r}
# checking each fips appears only 1x in cens
# otherwise left_join() will duplicate unnecessarily
sum(table(cens$fips))==length(unique(cens$fips)) 
```
--

... probably coming from multiple `NA` values (each state total)?

--
```{r}
cens <- cens[!is.na(cens$fips), ] # may be more than one NA here
sum(table(cens$fips))==length(unique(cens$fips))
```
--

Yay!

--
```{r, message=T}
cens$fips <- factor(cens$fips)
ct_test <- left_join(ct, cens, by="fips")
```

Translation: joining based on character strings rather than factor level numbers.

???
ok, now it's time to check.






---
## check merged dataset
```{r}
names(ct_test)
ct_test[, c("county.x", "fips", "county.y")]
```
???
this is why I left county and state in both datasets





---
## check merged dataset
Looks OK. (I'd usually do more spot-checking with the whole row)

--

Now let's get rid of duplicated columns.
```{r}
ct_test <- ct_test[, 1:13]
colnames(ct_test)[c(2, 3, 13)] <- c("county", "state", "pop")
```

--

We don't need `ct_test` anymore...
```{r}
ct <- ct_test
rm(ct_test) # delete
```





---
## head of ct with population
```{r, echo=F}
library(knitr)
library(kableExtra)
kable(head(ct), 'html') %>%
  kable_styling(bootstrap_options = c( "striped", "scale_down", "hover"), font_size=11)
```







---
## End Session 2


Next up:
- 3pm-4pm: Break & Exercises 2: 
  - perform the data manipulations here, then augment the data further with 2016 election results
  - perform your own EDA

- 4pm-5pm: Session 3: 
  - share some ggplot2 plots!
  - choropleth maps


Also: [ggplot2 cheatsheet](https://rstudio.com/wp-content/uploads/2016/11/ggplot2-cheatsheet-2.1.pdf) (published by Rstudio)

